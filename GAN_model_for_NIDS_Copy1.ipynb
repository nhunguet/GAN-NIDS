{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhunguet/GAN-NIDS/blob/main/GAN_model_for_NIDS_Copy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGR2OmPaDPT5"
      },
      "source": [
        "##Source and implement follow guide by Jason Brownlee,  https://machinelearningmastery.com/semi-supervised-generative-adversarial-network/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOzpB_vJeZwg",
        "outputId": "ca456f7e-6de1-4bee-e5da-d45213a2a71a"
      },
      "source": [
        "#Mount to google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4O0R17OeZzW"
      },
      "source": [
        "# Link to folder\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/NIDS (DNP3-GOOSE)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWWHHXm0eZ2A"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IfjTWE8DPFh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsvaahZR7mdx"
      },
      "source": [
        "# Deep Learning\n",
        "# Library\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "# Reading CSV\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tuesday  March  14:55:25 2021\n",
        "\n",
        "@author: Nhung Nguyen\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input, backend\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
        "from keras.models import Sequential, Model\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from keras.optimizers import Adam, SGD\n",
        "#import keras.backend.tensorflow_backend as K\n",
        "from math import sqrt\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "#mine\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.backend as K\n",
        "import keras\n",
        "from keras import utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten\n",
        "\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac6svP1FLfgw"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rfb4dk-7md4"
      },
      "source": [
        "train_df = pd.read_csv('extracted_dataset_DNP32.csv')\n",
        "\n",
        "scalers = {}\n",
        "train_X = None\n",
        "data = []\n",
        "le = preprocessing.LabelEncoder()\n",
        "for col_name in ('tot_dnp3_payload_len', 'rttd','min_payload_len','dst_bytes','flag','contains_dnp3_pckt',\n",
        "                 'srv_count','dst_host_count','func_code_not_supported_count','dst_host_same_srv_rate',\n",
        "                 'src_bytes','count'):\n",
        "\n",
        "#for col_name in ('path', 't','state','seq','data_cnt'):\n",
        "\n",
        "    if train_df[col_name].dtypes == object or train_df[col_name].dtypes == bool :\n",
        "        train_df[col_name] = le.fit_transform(train_df[col_name]) \n",
        "    scalers[col_name] = MinMaxScaler(feature_range=(0, 1))\n",
        "    data.append(scalers[col_name].fit_transform(np.array(train_df[col_name]).reshape(-1, 1)).reshape(-1))\n",
        "\n",
        "train_X = np.column_stack(data)\n",
        "train_X_rs = train_X.reshape(train_X.shape[0],train_X.shape[1])\n",
        "\n",
        "Y = list(train_df['label'])\n",
        "for i in range(len(Y)):\n",
        "    if Y[i] == 'normal':\n",
        "        Y[i] = 0.0 \n",
        "    elif Y[i] == 'dos':\n",
        "        Y[i] = 1.0 \n",
        "    else:\n",
        "        Y[i] = 1.0 # convert 'dos' to 1.0, other things to 0.0\n",
        "Y = np.array(Y)\n",
        "\n",
        "\n",
        "\n",
        "#train_X, X_test, Y, y_test = train_test_split(train_X, Y, test_size = 0.20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF12jiB1fU2o"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "#from sklearn import cross_validation\n",
        "#from sklearn.metrics import top_k_accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test =  train_test_split(train_X, Y, test_size=0.1)\n",
        "#svmClassifier = LinearSVC(random_state=11)\n",
        "#svmClassifier.fit(X_train, y_train)\n",
        "#y_pred = svmClassifier.predict(X_test)\n",
        "#metrics.accuracy_score(y_test, y_pred, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_wM3BD_e_0Y",
        "outputId": "21112502-e224-451f-f1b2-8c688c33c919"
      },
      "source": [
        "#SVM\n",
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(train_X, Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgVO3LIqe_6u",
        "outputId": "b8f0e123-29b1-420a-c862-f2e6697eeb6f"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(774, 12)\n",
            "(774,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLWWLgZYfpZR",
        "outputId": "34d87304-1f82-429f-b360-516b4fe63c6b"
      },
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "e3q0pQsbfAHn",
        "outputId": "735d9734-c8d8-4296-b700-94e6bbbb399a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='winter');\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "w = svc.coef_[0]\n",
        "a = -w[0] / w[1]\n",
        "xx = np.linspace(xlim[0], xlim[1])\n",
        "yy = a * xx - svc.intercept_[0] / w[1]\n",
        "plt.plot(xx, yy)\n",
        "yy = a * xx - (svc.intercept_[0] - 1) / w[1]\n",
        "plt.plot(xx, yy, 'k--')\n",
        "yy = a * xx - (svc.intercept_[0] + 1) / w[1]\n",
        "plt.plot(xx, yy, 'k--')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ea35e8ad0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxTVf7/8Xe6pWvSAi1lKSig7MoIChUQxQ6MIspXR/GrFlC+uFVcYBQYHBYXcJSfMuMCigs4M4ob7uiA4C4ODIijsjgMOqClBbRJ2Nomzf39EXtp2qSk0LS35fV8PPJok3ty78l5VPPmc88912YYhiEAAAALimnsDgAAAIRDUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJYV19gdOFZ+v1+FhYVKS0uTzWZr7O4AAIAIGIahffv2qW3btoqJCV83afJBpbCwUDk5OY3dDQAAcBR27typ9u3bh93e5INKWlqapMAHdTgcjdwbAAAQCY/Ho5ycHPN7PJwmH1QqT/c4HA6CCgAATcyRpm0wmRYAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFgWQQUAAFhWk78pIQAAODp+v1/79u2Ty+VSSUmJ+bOsrEyXX355Y3dPEkEFAIBm48svv1RhYWGN4OFyuRQTE6PHH3/cbDt8+HC999578vv9NfaTmppKUAEAADWrGuXl5TrjjDPM7Q8//LC+/fbbGsGjpKREKSkp+ve//222veGGG7RmzZqQx0lJSQkKKrGxsWZISUxMVHp6ujIyMsyffr9fMTGNP0OEoAIAQD3YvXu3fv7555CBwm6363e/+53Z9re//a02bNggl8slt9sdVNVo3769du7caT5//vnnaw0fVXXr1k2lpaVKT083A0fV8GEYhmw2myTpySeflM1mU0ZGhhITE+tzKOoVQQUAcNzz+/3yeDwqLS1Vdna2+foLL7ygH374IeSplKysLL366qtm27PPPlubN28Ouf/27dsHBZXCwkJ99913QW0qqxpVjy9JV111lYYOHWoGjuoBpKqnn3464s/ctm3biNs2JoIKAKBZKC0tDRkokpKS9D//8z9muwkTJmj79u1B7dxutwzDUK9evfTVV1+ZbWfNmqUtW7aEPF779u2Dnrdo0SKoelH1Z5s2bYLa/vnPf5bX6w0KH+GqGjfeeOPRDkmzQFABAFhC1dMSkvThhx/qp59+CnkqpV27drr//vvNtieccIL++9//htxvr169goLKJ598EjZ8HDp0KOj5iBEj1Ldv35ABpFWrVkFtP/7446D+16Zfv34RtYNkMwzDaOxOHAuPxyOn0ym32y2Hw9HY3QGA41ppaWlQoEhISAj6Uv7973+v4uLiGsGjpKREffr00QcffGC2zc7OVnFxccjjVK98dO/eXVu2bJHNZgs6PZKenq6TTjpJCxcuNNu+8sorKisrCzp9cqSqBupfpN/fVFQAAEEMw9D3338fspLhcrmUk5Oj6667zmx/2mmnadeuXeb6G1UNHjxYH330kfn8mWeeUVFRUcjj/vzzz0HPTz/9dP3888815mSkp6crJycnqO3q1auVnJystLS0I16pcskll0Q0DrAGggoANDOVVQ3DMMwJk36/XwsWLDCrF1WDh8vl0umnn25eumqz2dS9e/caoaPS4MGDg4LKrl27gsJHTEyMGSiqT9icNGlS0NyMqj9btGgR1PbNN9+M+DNXnwOC5oOgAgAWU1FRIbfbHbKa0bZtW51//vmSJJ/Pp5EjR5pho7JNZcAYOXKk3njjDUmB8DB58uSw4SM1NTXoedu2bVVWVhaymtGtW7egtq+99lrQOhypqalhqxq33377MY0Njj8EFQCoZ4ZhqKKiQnFxgf/Fer1erVixIuyplDPOOENTp06VFKiGJCUlhd33hRdeaAaVuLg4vf/++yHDR0xMjCoqKoJeu/LKKxUTExPyMtfqlY/t27dH/Hn79+8fcVugrggqABBCqKpGq1atdOqpp0qS9u/frzvuuCNk8CgpKdHll1+uJUuWmPu64IILaj1WpcTERNntdpWVlSk5ObnG6ZGqK5ZKgTkfiYmJNRb2ClXVeOqpp+preIAGQ1AB0Kx5vV59++23IQOFy+VSv3799L//+7+SpL1796pfv34qKSmRx+Opsa8xY8aY4SM2NlYLFiwIe1yXy2X+npiYqNzcXKWkpIScm3HSSScFvfeHH36Qw+FQQkLCET9fZd+B5oqgAsCyKqsaJSUlSk5ONidMulwuPfHEE2GrGaNHj9Zdd90lKRA+evXqFfYYY8aMMb/sU1JSaqzFkZycHHLRrqSkJM2aNUsOh6NGNSM9Pb3GxNDPPvss4s9dfX0O4HhGUAEQNYZh6NChQ2HnZpxyyikaMmSIpEAV4aqrrgraXrWqccstt2j+/PmSpIMHD2rKlClhj1s1bFSGhlBhIj09PehUSmJioj7//POg7bVVNWbOnHnUYwMgMgQVALWqqKiQz+eT3W6XFKhmrFy5Mmw149JLL9X48eMlSVu2bFGPHj3C7vuWW24xg0psbKw+/PDDkO2q33itRYsWys/PD7lUeUZGhjp06GC2TUpK0k8//RTRZ7XZbEwMBSyGoAI0c4Zh6ODBgzVCRZcuXdS9e3dJ0vfff6/Zs2eHDB8ej0ezZs0yqweFhYW67LLLwh6v6qWrlTdMi42NDXkn1z59+phtW7ZsqaVLl4asesTHxwcdIzExUc8++2y9jREA6yKoAE3IgQMHtHnz5rCnUi688EKdd955kqQNGzboN7/5jVwul7xeb419zZw5U7NmzZIUOJWyePHisMctKSkxf2/VqpUGDx5cI0xUhpDevXubbVu3bi2Px6PU1NQj3gMlISFBo0ePrsNoADgeEFSABlC9qpGVlaWsrCxJgWrGkiVLwp5K+f3vf6/rr79ekvTll19q4MCBYY+TnZ1tBpXExETt2bPH3Fa1qpGenm4eX5LatWunuXPnhqxmVL+VfFZWVtCS6LWJiYlRWlpa5AMFANUQVIAIVVRUhA0TLpdLeXl5Ou200yRJa9eu1cSJE4Mug61a1Zg/f75uueUWSYFTKZWVjVCq3pStZcuWat++fciJoRkZGTr77LPNtp07d9aXX35pbq+tquF0Os0FxwDASggqOG4YhqEDBw4oLi7OvEPqDz/8oFWrVtVYgrzy99/97ncaOXKkJOndd9+tddGu+fPnm0HF6/Vq7dq1NdrExcUpPT09KDBU3uAtVPBIT09Xx44dzbZdu3bVzp07I/q8drtdp5xySkRtAcCqGiyo3HfffZo2bVrQJYalpaWaPHmyli5dqrKyMg0fPlyPPfaYWrdu3VDdQhPj9XrNdTWqL0F+wgknSApUM/7f//t/IRf38vl8WrJkicaMGSMpcCpl3LhxYY938cUXm79Xnv5ITU0NGSq6du1qtu3Ro4def/31GqdQUlJSalQ1cnJygm5BDwA4rEGCyrp16/T444/X+NfdbbfdprffflsvvfSSnE6nbrrpJl188cX69NNPG6JbaGR79+7Vpk2bwp5OKSgoMNe4WLZsmcaOHav9+/eH3NeSJUvMoLJnzx69+OKLYY9bdWJoTk6Ohg0bFvKKlPT0dPXt29dsO2DAAHm9XvP+LbXJyMjQhRdeGMkwAABqEfWgsn//fl155ZVatGiR7rnnHvN1t9utp556Ss8995yGDh0qKXDPiu7du+vzzz/XgAEDot01HKXqVY0uXbooIyNDUuBKkxdffNEMG9UDyOLFizVixAhJgVMp+fn5YY9z7rnnmkHFbrcHhZS0tLSgUFF5fEnq3bu35s+fH/ZUStU1OU455RT9/e9/j+hzx8bGRj5IAIB6EfWgUlBQoBEjRigvLy8oqKxfv15er1d5eXnma926dVOHDh20Zs2asEGlrKws6E6hoe7HgSMrLS3V7t27w1Yz8vPz1aVLF0nSK6+8otmzZ5vbq1c1Xn/9dbN6sGnTJv3xj38Me9y9e/eav2dnZ+vkk08Ou2hX5XwPSRoyZIi2bdum9PR0OZ3OWqsaHTp0MCeqAgCatqgGlaVLl2rDhg1at25djW1FRUVKSEgIuuxRCqy7UFRUFHafc+fO1ezZs+u9r02N1+uVy+WSw+EwVwz95ptv9PHHH4cNHwsWLFC/fv0kSYsWLdLNN98cdv99+/Y1g8qhQ4f01Vdf1WhTWdWoqnfv3rr11lvDXuZadcXQvLw8bd26NaLPm5qaqtTU1IjaAgCaj6gFlZ07d+qWW27RypUrzSss6sO0adM0adIk87nH41FOTk697b+hGIah/fv3hwwUI0aMUGZmpqRAteKpp56q0e7AgQOSpI8++kiDBw+WJL3//vuaOHFi2GMWFhaav2dkZCguLi7sZa7t27c325577rlasWJFUNtwVY1TTz1VDz30UL2MEQAAUQsq69ev1+7du4PK9xUVFfroo4/0yCOP6O9//7vKy8vlcrmCqirFxcXKzs4Ou1+73W5WEKzkv//9r7Zs2RK2mvHHP/5RJ554oiRp3rx5mjp1qioqKkLu66OPPjKDys6dO/Xmm2+GPW7VU19du3bVqFGjwk4MPf300822V1xxha688sojrhYqSW3atAm6aywAAA0lakHl3HPPrXG64Oqrr1a3bt00ZcoU5eTkKD4+XqtWrdIll1wiSdq6dat27Nih3NzcaHWrTt59910tX7487AJfn3/+ublc+LPPPqsZM2aE3dfEiRPNoJKYmGiGlPj4+BqhIjk52XzfOeecoyeeeKLGxNHKqkbVCZ6//vWv9etf/zqizxYTE1Pn8QAAoKFFLaikpaWpV69eQa+lpKSoZcuW5uvjx4/XpEmT1KJFCzkcDk2cOFG5ubmWueJn3bp1evjhh8Nud7lc5u8dO3bUqaeeGvZKk8qQIkn5+fm6+OKLlZ6erqSkpFqrGj179lTPnj3r5wMBANDENOrKtA899JBiYmJ0ySWXBC34ZhWDBw/WtGnTwoaPqvM4xowZYy4idiROp1NOpzNa3QYAoNmwGYZhNHYnjoXH45HT6ZTb7ZbD4Wjs7gAAgAhE+v3NRAUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZUQ0qc+fO1emnn660tDRlZWVp1KhR2rp1a1Cb0tJSFRQUqGXLlkpNTdUll1yi4uLiaHYLAAA0EVENKh9++KEKCgr0+eefa+XKlfJ6vRo2bJgOHDhgtrntttv05ptv6qWXXtKHH36owsJCXXzxxdHsFgAAaCJshmEYDXWwPXv2KCsrSx9++KHOOussud1uZWZm6rnnntNvf/tbSdKWLVvUvXt3rVmzRgMGDDjiPj0ej5xOp9xutxwOR7Q/AgAAqAeRfn836BwVt9stSWrRooUkaf369fJ6vcrLyzPbdOvWTR06dNCaNWtC7qOsrEwejyfoAQAAmqcGCyp+v1+33nqrBg4cqF69ekmSioqKlJCQoPT09KC2rVu3VlFRUcj9zJ07V06n03zk5OREve8AAKBxNFhQKSgo0Ndff62lS5ce036mTZsmt9ttPnbu3FlPPQQAAFYT1xAHuemmm/TWW2/po48+Uvv27c3Xs7OzVV5eLpfLFVRVKS4uVnZ2dsh92e122e32qPcZAAA0vqhWVAzD0E033aRXX31Vq1ev1oknnhi0vW/fvoqPj9eqVavM17Zu3aodO3YoNzc3ml0DAABNQFQrKgUFBXruuef0+uuvKy0tzZx34nQ6lZSUJKfTqfHjx2vSpElq0aKFHA6HJk6cqNzc3Iiu+AEAAM1bVC9PttlsIV9/5plnNG7cOEmBBd8mT56s559/XmVlZRo+fLgee+yxsKd+quPyZAAAmp5Iv78bdB2VaCCoAADQ9FhyHRUAAIC6IKgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLimvsDhwPCvS2HtM/g177P/XRIl3USD0CAKBpIKhEWbbmqVgHarz+pDZqmbboJ01phF4BANA0cOoniibo9ZAhpdLPKtWleqEBe4Sj8dNPUlKSZLNJJ54oJSYGfrfZpKuvPvy7zWYoM2e/bIllsnX4Se0fWy1bjFc2e7mSh2yXLbNENptPNptPp57nli3HJVv6QfXqJcXFBfYRFyeNHn14n7f+vlw2W/kv76tQaurhbVdccfj3pKTGHqXQdu+W/vEPadMmyTAauze1KyuTNmyQ1q2TDlT7z/bgQemf/wxsLys7uv1XVEj/+ldgPEpKjr2/1RmGtGWL9PnnUlFR/e8f1nfgQODvd8MGqby8sXtTjwwLeOSRR4yOHTsadrvdOOOMM4x//OMfEb/X7XYbkgy32x3FHh4dGbMiesC6Av/7j/Th/+VR9Xmk22rbZ7h9hH5YwfffG8YllxhGTMzhfp18smG8+GJj96wmr9cw7rrLMFq0ONzX1FTDmDTJMH76yTAmTw48r9yWkWEYs2cH3hcJv98wFi40jJycw/uIjzeMceMMY8+e+vkMr75qGD16HN6/zWYYF15oGNu21c/+YW0HDhjGrbcaRkrK4b+Bli0N4557DMPna+zehRfp97fNMBr33zkvvPCCxowZo4ULF6p///6aP3++XnrpJW3dulVZWVlHfL/H45HT6ZTb7ZbD4WiAHkfOptkRtTM0M8o9wdGw2Y51D4akY95Jndlskt/f4Ic17dwpnX56oBLl8wX3yzCkhQul665rvP5VZRiBytQLL9Ss+NhsktMpeTw1x9Nmky67THr++SP/ncyYId19d83XY2OlTp0CFZaMjKP/DM8+K40de3h8q+7f6Qz8C7tTp6PfP6ytrEzKy5M++yz03+mVVwb+Ro79/2f1L9Lv70Y/9fPggw9qwoQJuvrqq9WjRw8tXLhQycnJevrppxu7aziOTZ9eH3tpnP8zNPYpljvvrBlSpMP9uuUWyeVq+H6F8t570tKlocfMMAL9DBX6DCMQblasqH3///mPdM89obdVVEjbt0vz5tW935X275duvPFwn6rv3+ORpk49+v3D+p59Vvrkk/B/p3/9q/TBBw3erXrVqEGlvLxc69evV15envlaTEyM8vLytGbNmkbsGY53c+Y0dg+OTa9ejXPcffsCVYbqIaWq8nLpuecark+1WbQoMC/oaMTFBd5fm6eflmJq+b9sRUWgwnS04fLllwPzZ8Lx+aRlywLBEc3TwoW1/41F8ndqdY0aVPbu3auKigq1bt066PXWrVurKMxssLKyMnk8nqAHgGDffNM4x921S/J6a28TFxeoJFjBt9/WHqpq4/MF3l+bSD7nzz/XnLwbqe3bjxy0KioCp+PQPG3fXvupXp9P+ve/G64/0dDop37qau7cuXI6neYjJyensbsEWE5ycuMcNz39yG38fqlFi+j3JRKZmbX/a7Q2MTFSq1a1t2nR4shzAxISjv6qrYyMQBA5EquMN+rfkeY3RfJ3anWNGlRatWql2NhYFRcXB71eXFys7OzskO+ZNm2a3G63+djJPxUQBU198uHR/gv9WGVlSWefHZjIGY7fH7gE2wquvPLoJx77/dJVV9Xe5n//t/aKTVycdPnltY9XbS69tPbtMTFS//5Shw5Ht39Y35gxtYdtvz/wd96UNWpQSUhIUN++fbVq1SrzNb/fr1WrVik3Nzfke+x2uxwOR9ADqG//+U9j96Dpuvvuw+u7VGezSddcI3Xu3PD9CuXyy6Vu3UKfPomNDXwBhAoRcXFS166BIFKbgQOlYcNC7yM2VoqPP7bJru3bBybThhtrSbr33qPfP6zvxhsDFZNwf2M9ex450Fpdo5/6mTRpkhYtWqQlS5Zo8+bNuuGGG3TgwAFdffXVjd21YxbJZcdcmmxdn30WaUvjl0eo55Fuq+s+aulNI1/1M2iQ9PrrUsuWgedxcYEv/JiYwGXJCxY0bv+qSkyU3n9fqvx3UdVg0r174Kqenj0DzyuDiyQNGBB435FO2dhs0iuvSP/zP4f3XxmK2raVVq0KHOdYPPSQNHFioH+ViwZKgdNwL78snXvuse0f1paVJX38cSBwS8F/p4MGBf7G7PbG6199aPR1VCTpkUce0QMPPKCioiL16dNHf/7zn9W/f/+I3mvldVSqqr6mCgGl6eja9ciTJgN+mSwQb0h2n2TzSft+mSxi90lpB6W9jsBVy533SiUpki9GOhQnlceH2J8hySep6j+Vwv/b4sYbpUcfjaSfDaO8XHrzzcDYORzSqFFSu3aN3avwvvgi8D/1iopAJWTgwMNrk3z2mfTpp4EvgKFDpdNOq/v+t22T3npLKi2VTjlFGj786E/5hLJrl/Tqq5LbHahYXXRR0/+CQuQMIxBY1qwJ/F3l5Ul9+jR2r2oX6fe3JYLKsWgqQQUAABzWZBZ8AwAACIegAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALIugAgAALCuusTsAAACsxzAMlXr9ch/yKikhVs6k+EbpB0EFAIBmqsJvyHPIK0+pV+5DXnkO+QI/zee//Cz1mc+rtvdWGJKkO0d01/8N7tQon4GgAgCARRmGoUPeiuCAcfDIwWPfL8Fjf5nvmPsQG2NTmc9fD5/m6BBUAACIIl+FX55SX5XqxZGrG1UrG5VVjWORkhArR1K8nEnxciTGy5EUL0dSnByJgdecSfFVtsfJmRxvbktOiJXNZquHkTg6BBUAAGpRWdVwH6oWMGoJHp4q2w+UVxxzH2JjbGaIcFQJFpVhwpEUZ4aQqqHDmRSvtMQ4xcc23WtnCCoAgGbvWKoa7kNe+fzHXtVI/mVCavWqRqiAYbWqRmMiqAAALM8wDB0sr/ilWhFc0WioqkZcZVXDrGbE1ahsVK9uOJpJVaMxEVQAAA3CW+H/Zd5F5KdOqratj6pGqj3OPH1Sdc5GbadPKl9Pij9+qxqNiaACAIhIZVUj+OqTcKGj5mmVg/VU1QieoxFX7ZRJ+NDhSIxTHFWNJoegAgDHkaOpalSds1FfVY3K0yFUNXAkBBUAaEIMw9CByqpGuAW7qoSOqs/rq6oRH2urNiG0ygTQI1Q30qhqoI4IKgDQwLwV/rCrggZXM2pekeIp9aminudqHPHUSXLwtsT4GKoaaDAEFQCoo+pVjUiWIq96WuWQl6oGECmCCoDjUuVcDXcjVjXS7FWvPomrdS2N4FVF45irgeMGQQVAk2QYhvaX+WpMAA2uZoSet1FfVY2E2Jgwi3aFuuIkeJ2NtMR4xcYQNIAjIagAaDTlPv8R7+Ja2xUp9VDUqFNVo/o9UexxzNUAoo2gAuCo1bWqUT10RKuqURk6Qi9NTlUDaEoIKsBxrswXuIX8ke51EtWqRmL4UyfV19FIq1rZSOQKFKC5I6gATZzfb2h/ue+XVUJDr59R22WwpV7/MfehsqrhTDp8uWv14BH6dvLxSk2Mo6oBICyCCmABlVWNSE6dVK9u7CuNXlUjZLgIcUolMT722DsAACEQVIB6YImqRlyMOfmz+nyMWpcmp6oBwMIIKsAv6lLVqD5foz6qGjZb4AqUqleY1JizUSNoxJnzOKhqAGiOCCpoNvx+Q/vKfLUu2BXtqoY9LkahVgitWtkwT6tUCx1p9jjFUNUAgCAEFVhKma8i+MqSUKdOqlc9frnd/L4yn4x6rmqEPHUStELo4QmkgStQqGoAQH0iqKBe1ahqVL+T6xHma5T56reqEereJ1WXIQ+ay5Ecr9QEqhoAYCUEFdRQ6q2odvrEF1S5CBk86rmqEerKk8owUVnxoKoBAM0fQaUZ8vsN7SutWb0It2jX4TaB95TXQ1UjMT6m2n1O4kJc5hp6sihVDQBAJYKKRVWvalSft1Fb6Nhfj1WNygAR+rLWqvdICQ4d9jiqGgCAY0dQiZIKv6H9Iaoa4cJFNKoaSfGxtaydUTNkUNUAAFgNQSUMwzBU6g11Z9fKeRo1qxtVw0d9VDVibKpxeqT6SqHhLoWlqgEAaA6iFlS+//573X333Vq9erWKiorUtm1bXXXVVZo+fboSEhLMdv/6179UUFCgdevWKTMzUxMnTtQdd9wRrW5F7N63N+vJT7475v3UtapRdb5GClUNAMBxLmpBZcuWLfL7/Xr88cfVpUsXff3115owYYIOHDigefPmSZI8Ho+GDRumvLw8LVy4UF999ZWuueYapaen69prr41W1yKSmhgYmsqqRm13dg1V1Qjc5ZWqBgAAx8JmGMd6giJyDzzwgBYsWKDt27dLkhYsWKDp06erqKjIrLJMnTpVr732mrZs2RLRPj0ej5xOp9xutxwOR7319UCZT37DoKoBAEAURPr9HdOAfZLb7VaLFi3M52vWrNFZZ50VdCpo+PDh2rp1q0pKShqyazWk2OOUlhhPSAEAoBE1WFDZtm2bHn74YV133XXma0VFRWrdunVQu8rnRUVFIfdTVlYmj8cT9AAAAM1TnYPK1KlTZbPZan1UP23z448/6je/+VMFbPQAAB5uSURBVI0uvfRSTZgw4Zg6PHfuXDmdTvORk5NzTPsDAADWVec5Knv27NFPP/1Ua5tOnTqZp3MKCwt19tlna8CAAVq8eLFiYg5nozFjxsjj8ei1114zX3v//fc1dOhQ/fzzz8rIyKix77KyMpWVlZnPPR6PcnJy6n2OCgAAiJ5I56jU+aqfzMxMZWZmRtT2xx9/1DnnnKO+ffvqmWeeCQopkpSbm6vp06fL6/UqPj5ekrRy5Up17do1ZEiRJLvdLrvdXtduAwCAJihqc1R+/PFHnX322erQoYPmzZunPXv2qKioKGjuyRVXXKGEhASNHz9e33zzjV544QX96U9/0qRJk6LVLQAA0IREbR2VlStXatu2bdq2bZvat28ftK3ybJPT6dSKFStUUFCgvn37qlWrVpoxY0ajr6ECAACsoUHXUYmGaK2jAgAAoseS66gAAADUBUEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYFkEFAABYVoMElbKyMvXp00c2m00bN24M2vavf/1LgwcPVmJionJycnT//fc3RJcAAEAT0CBB5Y477lDbtm1rvO7xeDRs2DB17NhR69ev1wMPPKBZs2bpiSeeaIhuAQAAi4uL9gHeeecdrVixQq+88oreeeedoG1/+9vfVF5erqeffloJCQnq2bOnNm7cqAcffFDXXntttLsGAAAsLqoVleLiYk2YMEF/+ctflJycXGP7mjVrdNZZZykhIcF8bfjw4dq6datKSkpC7rOsrEwejyfoAQAAmqeoBRXDMDRu3Dhdf/316tevX8g2RUVFat26ddBrlc+LiopCvmfu3LlyOp3mIycnp347DgAALKPOQWXq1Kmy2Wy1PrZs2aKHH35Y+/bt07Rp0+q1w9OmTZPb7TYfO3furNf9AwAA66jzHJXJkydr3Lhxtbbp1KmTVq9erTVr1shutwdt69evn6688kotWbJE2dnZKi4uDtpe+Tw7Ozvkvu12e419AgCA5qnOQSUzM1OZmZlHbPfnP/9Z99xzj/m8sLBQw4cP1wsvvKD+/ftLknJzczV9+nR5vV7Fx8dLklauXKmuXbsqIyOjrl0DAADNTNSu+unQoUPQ89TUVElS586d1b59e0nSFVdcodmzZ2v8+PGaMmWKvv76a/3pT3/SQw89FK1uAQCAJiTqlyfXxul0asWKFSooKFDfvn3VqlUrzZgxg0uTAQCAJMlmGIbR2J04Fh6PR06nU263Ww6Ho7G7AwAAIhDp9zf3+gEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJYV1aDy9ttvq3///kpKSlJGRoZGjRoVtH3Hjh0aMWKEkpOTlZWVpdtvv10+ny+aXQIAAE1IXLR2/Morr2jChAmaM2eOhg4dKp/Pp6+//trcXlFRoREjRig7O1ufffaZdu3apTFjxig+Pl5z5syJVrcAAEATYjMMw6jvnfp8Pp1wwgmaPXu2xo8fH7LNO++8owsuuECFhYVq3bq1JGnhwoWaMmWK9uzZo4SEhIiO5fF45HQ65Xa75XA46u0zAACA6In0+zsqp342bNigH3/8UTExMfrVr36lNm3a6LzzzguqqKxZs0a9e/c2Q4okDR8+XB6PR998803YfZeVlcnj8QQ9AABA8xSVoLJ9+3ZJ0qxZs3TnnXfqrbfeUkZGhs4++2z9/PPPkqSioqKgkCLJfF5UVBR233PnzpXT6TQfOTk50fgIAADAAuoUVKZOnSqbzVbrY8uWLfL7/ZKk6dOn65JLLlHfvn31zDPPyGaz6aWXXjqmDk+bNk1ut9t87Ny585j2BwAArKtOk2knT56scePG1dqmU6dO2rVrlySpR48e5ut2u12dOnXSjh07JEnZ2dlau3Zt0HuLi4vNbeHY7XbZ7fa6dBsAADRRdQoqmZmZyszMPGK7vn37ym63a+vWrRo0aJAkyev16vvvv1fHjh0lSbm5ubr33nu1e/duZWVlSZJWrlwph8MRFHAAAMDxKyqXJzscDl1//fWaOXOmcnJy1LFjRz3wwAOSpEsvvVSSNGzYMPXo0UP5+fm6//77VVRUpDvvvFMFBQVUTAAAgKQorqPywAMPKC4uTvn5+Tp06JD69++v1atXKyMjQ5IUGxurt956SzfccINyc3OVkpKisWPH6q677opWlwAAQBMTlXVUGhLrqAAA0PQ06joqAAAA9YGgAgAALIugAgAALIugAgAALIugAgAALCtqlycDAADrMgxD+/btU0lJiVwuV9BPr9era6+9trG7KImgAgBAk+X1ehUfH28+/+STT7Rz504zcFQNH7GxsXrhhRfMtmeddZY++eSTkPtNSUkhqAAAcLzz+/01qhoVFRXKy8sz28yZM0ebN28OWfnIyMjQjz/+aLadMmWKPvvss5DHSk5ODnpeuXaJ3W5XRkaG0tPTg376/X7FxDT+DBGCCgAA9WDbtm3au3dvyECRlJQUtPL68OHDtW7dOrndbvn9/qD9tGvXTj/88IP5/O233w4bPmw2W9Dzynvtpaenm4GjavgwDMN8z3PPPaeEhAQlJSXV1xBEBSvTAgCOa1WrGl6vVyeddJK5bdGiRdqxY0eN4OFyuZSdna1Vq1aZbXv27KlNmzaFPEb18DFw4MCg8FG1qtGuXTu999575ra//OUv2r17txk2nE5njQDSFEX6/U1FBQDQ5JWWlsrlctUIFCUlJUpNTdXYsWPNtqNHj9a2bdvMdlWrGj179tTXX39ttn3ooYe0efPmkMd0u91Bzzt06KBDhw7VOIWSnp6u7OzsoLZPPvmkJJnbExMTw362/Pz8ug1GM0NQAQA0Or/fr9LS0qB5FG+88Yb27NkTsprRoUMHLViwwGzbqVMn7dq1K+S+e/bsGRRUvvrqq5DhIzExUQkJCUGvjR49Wnv27Ak5h6Nly5ZBbd95552IP2/37t0jbnu8I6gAAOpFZVWjaqhISUnRkCFDzDY33XSTdu3aVaOd2+3WwIED9fHHH5ttr7vuOhUVFYU8Vs+ePYOep6enq6ioyDwtUjVUdOrUKajtQw89pIqKiqDTJ+GqGjNnzjyWIUE9IKgAAIIYhqGNGzeGnBTqcrl04oknavLkyWb7zp07q7CwUKWlpTX2NWjQoKDwsWzZsrCVD5fLFfT83HPPlcvlCgodlY927doFtV27dq2Sk5Mjukpl+PDhR2wD6yCoAEAzcujQITNUxMfHmxND/X6/5syZY4aN6uts5Obm6rnnnpMUuJLkzDPPDBk8pED4qBpUDh06ZLa12WxBwaJbt25B7505c6ZZzQg1l6Oqv/71rxF/7tTU1IjbomkhqACAhRiGETJIVP484YQT9Nvf/laS5PP5NHjw4KDtZWVl5r4uuOACvfnmm5KkmJgY3XvvvWHDR/v27YOed+vWTeXl5TUucU1PTw+6KkaSVq1apeTkZKWnpystLa3WqsZ11113VOOC4xdBBQDq2aFDh+Tz+ZSWliZJKi8v10svvRT2VMqgQYPMNTbKysrUokWLsPseOXKkGVTi4uK0cePGGuGjsqpRfYGvG264QbGxsUGhozKEZGVlBbX94osvIv68TAxFNBFUAKCaiooKeTyeGoGibdu2ys3NlSTt27dP1113XcjgUVZWpvz8fD377LOSAqddrrrqqrDHq3raIjExUYmJiYqJiQl5aqRfv35B733llVeUnJwc1C41NTVkVePBBx+sj+EBGhRBBUCzVlZWpn/+859hqxkDBw7U+PHjJUl79uxRly5d5PF4Qu4rPz/fDCrx8fF6/vnnwx636sTQxMREnXfeeUpJSQk5N+PEE08Meq/b7a5xmWw4559/fkTtgKaKoALAkioqKuR2u4PuaVJ5menPP/+sefPmhQweJSUlys/P17x58yRJJSUlGjRoUNjj+Hw+M6ikpaUFhZTKeReVoaLq3IzExETNnz9fDoejxiqhlXM1qlq+fHnEnz3SkAIcDwgqAKLG5/Np9+7dYasZZ5xxhnmp6I4dO3ThhRea26tXNW6++Wb96U9/khSY8zF37tywx929e7f5e0ZGhjp37lwjSFQ+fvWrX5ltExMTtWXLFrPNkQLDLbfcUucxAVA3BBUAYVVUVMjlcikuLk5Op1OS9NNPP2nZsmVhqxlXXXWVbrrpJknSv//9b/Xo0SPs/m+++WYzqCQkJOjLL7+s0SYlJUXp6elKSUkxX8vIyNDNN98ccg5HRkZG0HLldrtd27Zti/gzd+3aNeK2AKKPoAI0Y4Zh6ODBgyFDRe/evdWnTx9J0n/+8x9Nnjy5xr1SKqsaM2bM0OzZsyUFqhXXXntt2GP279/f/D0jI0OxsbFh7+R65plnmm1btmypd999N2i70+kMWdWw2+1mdQVA80ZQAZoQt9uttWvXhgweLpdLo0eP1qhRoyRJ69at08CBA+X1ekPua8aMGWZQKS8v1+uvvx72uPv37zd/z8zM1MiRI2ucRqkMISeffLLZtnXr1vJ6vTVuRR9KfHw8K4YCqIGgAkRZqKpGx44dlZOTI0natm2bHn300bCnUu6++25zLsSmTZs0bNiwsMfq2rWrGVRSU1PNkFJ17YzKnyeccIL5vvbt22vBggVh53FUrWq0atVKb7zxRkSfPZKAAgC1IagAETp06JB+/PHHGkuQV/688MILzUtXP/30U11zzTXm9upVjYceeki33nqrpMAlsfPnzw973JKSEvP3zMxM9erVK+RVJhkZGebxJalLly7asWOHMjIylJKSUmtoSEtL0/XXX39U4wIA0URQwXHBMAwdOHBALpdLTqfTvHT0u+++0xtvvBEyeLhcLv3hD38wVwF9//33NWLEiLDHaN26tRkUbDabvv3226DtVasaVVcM7dixo6ZMmRL23idVJ4Z26dJFX331VUSfOT4+3qzaAEBTRVBBk+Hz+cLOzTjnnHPMNS4++eQT3X333TXa+Xw+SdLixYs1duxYSdLmzZvNykYoP/zwg/l75Yqf4a40OfXUU822vXr10ocffhh0CiU1NTVkVaNt27a677776mWMAKC5IaigwRiGIcMwzKW9CwsL9c9//jPs3Izbb7/dXKjrhRde0OWXXx5234sXLzaDisfj0YoVK0K2i4uL06FDh8znJ5xwgkaPHh1yYmh6enrQpbW5ubnat29fRJ/V4XDorLPOiqgtACA8ggrqxOv1yu12B1Uz+vTpo8zMTEnSmjVrtHjx4rCnUl5++WVddNFFkgKnUmq7/8nFF19sBpWqq3ympqYGVTIyMjLUpk0bc3ufPn20ZMmSkFWP5OTkoKpGjx49tHTp0nodIwBA/SGoHKdcLpd27NgRtppxww03qFu3bpKk559/XnfccYdcLlfQZaqVXnvtNTN8bN++XU888UTY41adGNq+fXudccYZNcJE5e9VJ4YOHTpUe/fuldPpVFxc7X+2bdu21ZgxY+o0HgAAayKoNEFer9esWLRr186cmLlhwwatWLEibPh49tlnzS//v/71r5o4cWLYYwwdOtQMKn6/P2iuhhSocFQGi6qXrv7qV7/SrFmzQl7mmpGRYVZeJGnIkCH6xz/+EdFnrryjLADg+EJQaQSVV6CEChMlJSW6/PLLzSs9XnzxRT3yyCPmNpfLpQMHDpj7+vDDD825EGvWrNG0adPCHrfq/U8yMzOVlZUVdmJo586dzbbDhw/X2rVrg0JHuKpGjx49NHPmzGMaHwAAKhFUjpLX61VMTIxiY2MlSVu2bNHGjRvDzs147LHH1KVLF0nSnDlzdOedd4bd92mnnWYGlT179ujjjz8O2S4tLU2lpaXm8969e2vcuHEhlypPT09Xz549zbajR4/W6NGjI/qsrVq1UqtWrSJqCwBAfSKo1OK1117TsmXLQlY+Dh48qC+//FKnnHKKJOnll1/WH/7wh7D7KiwsNINKenq6pMA6F6GqGZU3f5MC1YwXX3yxximUUHM1zjrrLK40AQA0KwSVWnz99df6y1/+Ena7y+Uyfz/ppJM0ZMiQsIt2Vb3/yTXXXKOrr75aSUlJR1xivEuXLmbAAQDgeGMzDMNo7E4cC4/HI6fTKbfbLYfDUa/7/vzzz/Xxxx+HDR/p6enmmiAAACBykX5/U1GpxYABAzRgwIDG7gYAAMctygEAAMCyCCoAAMCyCCoAAMCyCCoAAMCyCCoAAMCyohZUvv32W1100UVq1aqVHA6HBg0apPfffz+ozY4dOzRixAglJycrKytLt99+u3w+X7S6BAAAmpioBZULLrhAPp9Pq1ev1vr163XqqafqggsuUFFRkSSpoqJCI0aMUHl5uT777DMtWbJEixcv1owZM6LVJQAA0MREZcG3vXv3KjMzUx999JEGDx4sSdq3b58cDodWrlypvLw8vfPOO7rgggtUWFio1q1bS5IWLlyoKVOmaM+ePUF35K1NNBd8AwAA0RHp93dUKiotW7ZU165d9eyzz+rAgQPy+Xx6/PHHlZWVpb59+0oK3Om3d+/eZkiRAve18Xg8+uabb8Luu6ysTB6PJ+gBAACap6isTGuz2fTee+9p1KhRSktLU0xMjLKysvTuu+8qIyNDklRUVBQUUiSZzytPD4Uyd+5czZ49OxrdBgAAFlOnisrUqVNls9lqfWzZskWGYaigoEBZWVn6+OOPtXbtWo0aNUojR47Url27jqnD06ZNk9vtNh87d+48pv0BAADrqlNFZfLkyRo3blytbTp16qTVq1frrbfeUklJiXne6bHHHtPKlSu1ZMkSTZ06VdnZ2Vq7dm3Qe4uLiyVJ2dnZYfdvt9tlt9vr0m0AANBE1SmoZGZmKjMz84jtDh48KEk17iwcExMjv98vScrNzdW9996r3bt3KysrS5K0cuVKORwO9ejRoy7dAgAAzVRU5qjk5uYqIyNDY8eO1YwZM5SUlKRFixbpu+++04gRIyRJw4YNU48ePZSfn6/7779fRUVFuvPOO1VQUFCniknlRUtMqgUAoOmo/N4+4sXHRpSsW7fOGDZsmNGiRQsjLS3NGDBggLF8+fKgNt9//71x3nnnGUlJSUarVq2MyZMnG16vt07H2blzpyGJBw8ePHjw4NEEHzt37qz1ez4q66g0JL/fr8LCQqWlpclmszV2d2rl8XiUk5OjnTt3subLMWAc6wfjWD8Yx/rBONaPpjSOhmFo3759atu2bY2pIlVF5dRPQ4qJiVH79u0buxt14nA4LP8H1BQwjvWDcawfjGP9YBzrR1MZR6fTecQ23JQQAABYFkEFAABYVuysWbNmNXYnjiexsbE6++yzFRfX5M+6NSrGsX4wjvWDcawfjGP9aG7j2OQn0wIAgOaLUz8AAMCyCCoAAMCyCCoAAMCyCCoAAMCyCCr17NFHH9UJJ5ygxMRE9e/fv8Ydoqt76aWX1K1bNyUmJqp3795avnx5A/XU2uoyjosWLdLgwYOVkZGhjIwM5eXlHXHcjxd1/XustHTpUtlsNo0aNSrKPWwa6jqOLpdLBQUFatOmjex2u04++WT+21bdx3H+/Pnq2rWrkpKSlJOTo9tuu02lpaUN1Fvr+eijjzRy5Ei1bdtWNptNr7322hHf88EHH+i0006T3W5Xly5dtHjx4uh3tL7V6cY6qNXSpUuNhIQE4+mnnza++eYbY8KECUZ6erpRXFwcsv2nn35qxMbGGvfff7+xadMm48477zTi4+ONr776qoF7bi11HccrrrjCePTRR40vvvjC2Lx5szFu3DjD6XQaP/zwQwP33FrqOo6VvvvuO6Ndu3bG4MGDjYsuuqiBemtddR3HsrIyo1+/fsb5559vfPLJJ8Z3331nfPDBB8bGjRsbuOfWUtdx/Nvf/mbY7Xbjb3/7m/Hdd98Zf//73402bdoYt912WwP33DqWL19uTJ8+3Vi2bJkhyXj11Vdrbb99+3YjOTnZmDRpkrFp0ybj4YcfNmJjY4133323gXpcPwgq9eiMM84wCgoKzOcVFRVG27Ztjblz54Zsf9lllxkjRowIeq1///7GddddF9V+Wl1dx7E6n89npKWlGUuWLIlWF5uEoxlHn89nnHnmmcaTTz5pjB07lqBi1H0cFyxYYHTq1MkoLy9vqC42CXUdx4KCAmPo0KFBr02aNMkYOHBgVPvZVEQSVO644w6jZ8+eQa+NHj3aGD58eDS7Vu849VNPysvLtX79euXl5ZmvxcTEKC8vT2vWrAn5njVr1gS1l6Thw4eHbX88OJpxrO7gwYPyer1q0aJFtLppeUc7jnfddZeysrI0fvz4huim5R3NOL7xxhvKzc1VQUGBWrdurV69emnOnDmqqKhoqG5bztGM45lnnqn169ebp4e2b9+u5cuX6/zzz2+QPjcHzeU7pnksW2cBe/fuVUVFhVq3bh30euvWrbVly5aQ7ykqKgrZvqioKGr9tLqjGcfqpkyZorZt29b4D/R4cjTj+Mknn+ipp57Sxo0bG6KLTcLRjOP27du1evVqXXnllVq+fLm2bdumG2+8UV6vVzNnzmyIblvO0YzjFVdcob1792rQoEEyDEM+n0/XX3+9fv/73zdEl5uFcN8xHo9Hhw4dUlJSUiP1rG6oqKBZue+++7R06VK9+uqrSkxMbOzuNBn79u1Tfn6+Fi1apFatWjV2d5o0v9+vrKwsPfHEE+rbt69Gjx6t6dOna+HChY3dtSblgw8+0Jw5c/TYY49pw4YNWrZsmd5++23dfffdjd01NDAqKvWkVatWio2NVXFxcdDrxcXFys7ODvme7OzsOrU/HhzNOFaaN2+e7rvvPr333ns65ZRTotlNy6vrOP7nP//R999/r5EjR5qv+f1+SVJcXJy2bt2qzp07R7fTFnQ0f49t2rRRfHy8YmNjzde6d++uoqIilZeXKyEhIap9tqKjGcc//OEPys/P1//93/9Jknr37q0DBw7o2muv1fTp0xUTw7+zjyTcd4zD4Wgy1RSJikq9SUhIUN++fbVq1SrzNb/fr1WrVik3Nzfke3Jzc4PaS9LKlSvDtj8eHM04StL999+vu+++W++++6769evXEF21tLqOY7du3fTVV19p48aN5uPCCy/UOeeco40bNyonJ6chu28ZR/P3OHDgQG3bts0MepL07bffqk2bNsdlSJGObhwPHjxYI4xUhj+DW9RFpNl8xzT2bN7mZOnSpYbdbjcWL15sbNq0ybj22muN9PR0o6ioyDAMw8jPzzemTp1qtv/000+NuLg4Y968ecbmzZuNmTNncnmyUfdxvO+++4yEhATj5ZdfNnbt2mU+9u3b11gfwRLqOo7VcdVPQF3HcceOHUZaWppx0003GVu3bjXeeustIysry7jnnnsa6yNYQl3HcebMmUZaWprx/PPPG9u3bzdWrFhhdO7c2bjssssa6yM0un379hlffPGF8cUXXxiSjAcffND44osvjP/+97+GYRjG1KlTjfz8fLN95eXJt99+u7F582bj0Ucf5fJkGMbDDz9sdOjQwUhISDDOOOMM4/PPPze3DRkyxBg7dmxQ+xdffNE4+eSTjYSEBKNnz57G22+/3cA9tqa6jGPHjh0NSTUeM2fObPiOW0xd/x6rIqgcVtdx/Oyzz4z+/fsbdrvd6NSpk3HvvfcaPp+vgXttPXUZR6/Xa8yaNcvo3LmzkZiYaOTk5Bg33nijUVJS0gg9t4b3338/5P/rKsdt7NixxpAhQ2q8p0+fPkZCQoLRqVMn45lnnmnwfh8rm2FQQwMAANbEHBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZ/x/JdBMrzUx05QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBDUSnQ27md5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c336acee-00e4-4068-99ed-0e45049da392"
      },
      "source": [
        "y_pred = svc.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[41,  0],\n",
              "       [ 2, 44]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98LA9O6e7md8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556d3623-89dc-4b76-adb1-53d805a57d71"
      },
      "source": [
        "# data split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_X_rs, Y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "                                                    # stratify = y: means make train and test set have same distribution"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(688, 12)\n",
            "(688,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6c6zlkN7md8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88c8715-80db-4f57-fdba-326b1b6cb732"
      },
      "source": [
        "print('X_train: ',X_train.shape)\n",
        "print('y_train: ',y_train.shape)\n",
        "print('X_test: ',X_test.shape)\n",
        "print('y_test: ',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (688, 12)\n",
            "y_train:  (688,)\n",
            "X_test:  (173, 12)\n",
            "y_test:  (173,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3dcADw7md-"
      },
      "source": [
        "####GAN MODEL\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAwQecRk7md-"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LeakyReLU, ReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Activation\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras import backend\n",
        "from keras.initializers import RandomNormal\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Pzk8lX7md_"
      },
      "source": [
        "\n",
        "#===============================================================================================Custom \n",
        "# custom activation function\n",
        "def custom_activation(output):\n",
        "    logexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
        "    result = logexpsum / (logexpsum + 1.0)\n",
        "    return result\n",
        "\n",
        "# Define some loss and optimizer function\n",
        "Category_loss = 'sparse_categorical_crossentropy'\n",
        "Binary_loss = 'binary_crossentropy'\n",
        "\n",
        "# Adam optimazation\n",
        "def Adam_optimizer():\n",
        "    return Adam(lr = 0.0002, beta_1 = 0.5)\n",
        "\n",
        "# RMS optimazation\n",
        "def RMS_optimizer():\n",
        "    return RMSprop(lr = 0.0002, decay = 6e-8)\n",
        "\n",
        "\n",
        "#===============================================================================================Create discriminator ================================\n",
        "\n",
        "# define the standalone supervised and unsupervised discriminator models\n",
        "def define_discriminator(in_shape=(12, 1), n_classes=2):\n",
        "     # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # image input\n",
        "    in_image = Input(shape=in_shape, name = 'Input')\n",
        "    \n",
        "    # downsample to \n",
        "    fe = Conv1D(128, 3, strides = 2, padding='same', kernel_initializer=init, name='conv2d_1')(in_image)\n",
        "    fe = LeakyReLU(alpha=0.2, name='Leaky_ReLU_1')(fe)\n",
        "    fe = Dropout(0.3, name='drop_1')(fe)\n",
        "    \n",
        "    # normal\n",
        "    fe = Conv1D(128, 3, strides = 2, padding='same', kernel_initializer=init, name='conv2d_2')(fe)\n",
        "    fe = BatchNormalization(name='Bat_Norm_1')(fe)\n",
        "    fe = LeakyReLU(alpha=0.2, name='Leaky_ReLU_2')(fe)\n",
        "    fe = Dropout(0.3, name='drop_2')(fe)\n",
        "    \n",
        "    # downsample to\n",
        "    fe = Conv1D(128, 3, strides = 2, padding='same', kernel_initializer=init, name='conv2d_3')(fe)\n",
        "    fe = BatchNormalization(name='Bat_Norm_2')(fe)\n",
        "    fe = LeakyReLU(alpha=0.2, name='Leaky_ReLU_3')(fe)\n",
        "    fe = Dropout(0.3, name='drop_3')(fe)\n",
        "    \n",
        "    # # normal\n",
        "    fe = Conv1D(256,3, padding='same', kernel_initializer=init, name='conv2d_4')(fe)\n",
        "    fe = BatchNormalization(name='Bat_Norm_3')(fe)\n",
        "    fe = LeakyReLU(alpha=0.2, name='Leaky_ReLU_4')(fe)\n",
        "    fe = Dropout(0.3, name='drop_4')(fe)\n",
        "    \n",
        "    # normal\n",
        "    fe = Conv1D(256,5, padding='same', kernel_initializer=init, name='conv2d_5')(fe)\n",
        "    fe = BatchNormalization(name='Bat_Norm_4')(fe)\n",
        "    fe = LeakyReLU(alpha=0.2, name='Leaky_ReLU_5')(fe)\n",
        "    fe = Dropout(0.3, name='drop_5')(fe)\n",
        "    \n",
        "    # flatten feature maps\n",
        "    fe = Flatten(name='Flatten_1')(fe)\n",
        "    \n",
        "    # dropout\n",
        "    fe = Dropout(0.4)(fe)\n",
        "    \n",
        "    # output layer nodes\n",
        "    fe = Dense(n_classes)(fe)\n",
        "    \n",
        "    # supervised output\n",
        "    c_out_layer = Activation('softmax')(fe)\n",
        "    # define and compile  discriminator model\n",
        "    c_model = Model(in_image, c_out_layer)\n",
        "    c_model.compile(loss=Category_loss, optimizer=Adam_optimizer(), metrics=['accuracy'])\n",
        "    \n",
        "    # unsupervised output\n",
        "    d_out_layer = Lambda(custom_activation)(fe)\n",
        "    # define and compile unsupervised discriminator model\n",
        "    d_model = Model(in_image, d_out_layer)\n",
        "    d_model.compile(loss=Binary_loss, optimizer=Adam_optimizer())\n",
        "    \n",
        "    return d_model, c_model\n",
        "\n",
        "\n",
        "#=============================================created gennerator ===================================================\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    depth = 1 #32\n",
        "    ks = 3\n",
        "    dropout = 0.25\n",
        "    dim = 12 #\n",
        "\n",
        "    # label input\n",
        "    in_label = Input(shape=(1,))\n",
        "    \n",
        "    # embedding for categorical input\n",
        "    li = Embedding(2, 50)(in_label)# ?\n",
        "    \n",
        "    # linear multiplication\n",
        "    n_nodes = 12 * 1\n",
        "    li = Dense(n_nodes)(li)\n",
        "    \n",
        "    # reshape to additional channel\n",
        "    li = Reshape((12, 1, 1))(li)\n",
        "    \n",
        "    # image generator input\n",
        "    in_lat = Input(shape=(latent_dim,))\n",
        "    # image generator input\n",
        "    in_lat = Input(shape=(latent_dim,), name='Generator_Input')\n",
        "    # foundation for 12x1\n",
        "    \n",
        "    gen = Dense(n_nodes, kernel_initializer=init, name='dense_4')(in_lat)\n",
        "    gen = Activation('relu', name='activation_1')(gen)\n",
        "    gen = Reshape((dim, 1, depth), name='reshape_2')(gen)\n",
        "    \n",
        "    # upsample to \n",
        "    gen = Conv2DTranspose(24, (5,5), strides=(1,1), padding='same', kernel_initializer=init, name='conv2d_transpose_1')(gen)\n",
        "    gen = BatchNormalization(name='Bat_Norm_5')(gen)\n",
        "    gen = Activation('relu', name='activation_2')(gen)\n",
        "    \n",
        "    # upsample to \n",
        "    gen = Conv2DTranspose(1, (5,5), strides=(1,1), padding='same', kernel_initializer=init, name='conv2d_transpose_2')(gen)\n",
        "    \n",
        "    # output    \n",
        "    out_layer = Activation('tanh', name='activation_3')(gen)\n",
        "    \n",
        "    # define model\n",
        "    model = Model(in_lat, out_layer)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "#========================================================================Define_gan========================\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    \n",
        "    # connect image output from generator as input to discriminator\n",
        "    gan_output = d_model(g_model.output)\n",
        "    \n",
        "    # define gan model as taking noise and outputting a classification\n",
        "    model = Model(g_model.input, gan_output)\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(loss=Binary_loss, optimizer=Adam_optimizer())\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "#define more function\n",
        "\n",
        "# load Data\n",
        "def load_real_samples():\n",
        "    # load dataset\n",
        "    (trainX, trainy) = (X_train, y_train)\n",
        "    \n",
        "    # expand to 3d, e.g. add channels\n",
        "    X = expand_dims(trainX, axis=-1)\n",
        "    \n",
        "    print('Shape of training dataset: ', 'X_train: ',X.shape, 'y_train: ',trainy.shape)\n",
        "    return [X, trainy]\n",
        "\n",
        "# select a supervised subset of the dataset, ensures classes are balanced\n",
        "def select_supervised_samples(dataset, n_samples=800, n_classes=2):\n",
        "    X, y = dataset\n",
        "    X_list, y_list = list(), list()\n",
        "    n_per_class = int(n_samples / n_classes)\n",
        "    for i in range(n_classes):\n",
        "        # get all images for this class\n",
        "        X_with_class = X[y == i]\n",
        "        # choose random instances\n",
        "        ix = randint(0, len(X_with_class), n_per_class)\n",
        "        # add to list\n",
        "        [X_list.append(X_with_class[j]) for j in ix]\n",
        "        [y_list.append(i) for j in ix]\n",
        "    return asarray(X_list), asarray(y_list)\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    # split into images and labels\n",
        "    images, labels = dataset\n",
        "    # choose random instances\n",
        "    ix = randint(0, images.shape[0], n_samples)\n",
        "    # select images and labels\n",
        "    X, labels = images[ix], labels[ix]\n",
        "    # generate class labels\n",
        "    y = ones((n_samples, 1))\n",
        "    return [X, labels], y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    z_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    z_input = z_input.reshape(n_samples, latent_dim)\n",
        "    return z_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    z_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    images = generator.predict(z_input)\n",
        "    # create class labels\n",
        "    y = zeros((n_samples, 1))\n",
        "    return images, y\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, c_model, latent_dim, dataset, n_samples=50):\n",
        "    # prepare fake examples\n",
        "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    # scale from [-1,1] to [0,1]\n",
        "    X = (X + 1) / 2.0\n",
        "    \n",
        "    # evaluate the classifier model\n",
        "    X, y = dataset\n",
        "    _, acc = c_model.evaluate(X, y, verbose=0)\n",
        "    print('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
        "    \n",
        "    # save the generator model\n",
        "    filename1 = 'g_model_SGAN_%04d.h5' % (step+1)\n",
        "    g_model.save('Save_Model/SGAN/' + filename1)\n",
        "    \n",
        "    # save the classifier model\n",
        "    filename2 = 'c_model_SGAN_%04d.h5' % (step+1)\n",
        "    c_model.save('Save_Model/SGAN/' + filename2)\n",
        "    print('>>Saved: %s, and %s' % (filename1, filename2))\n",
        "    print()\n",
        "#train model \n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, c_model, gan_model, dataset, latent_dim, n_epochs=50, n_batch=100):\n",
        "    # select supervised dataset\n",
        "    X_sup, y_sup = select_supervised_samples(dataset)\n",
        "    print('Supervised dataset: ', X_sup.shape, y_sup.shape)\n",
        "    \n",
        "    # calculate the number of batches per training epoch\n",
        "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "    \n",
        "    # calculate the number of training iterations\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "    \n",
        "    # calculate the size of half a batch of samples\n",
        "    half_batch = int(n_batch / 2)\n",
        "    print('n_epochs = %d, n_batch = %d, half_batch = %d, bat_per_epo = %d, steps = %d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
        "    \n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_steps):\n",
        "        # update supervised discriminator (c)\n",
        "        [Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
        "        c_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
        "        \n",
        "        # update unsupervised discriminator (d)\n",
        "        [X_real, _], y_real = generate_real_samples(dataset, half_batch)\n",
        "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "        \n",
        "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "        \n",
        "        # update generator (g)\n",
        "        X_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
        "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "        \n",
        "        # summarize loss on this batch\n",
        "        print('step: %d,  c[%.3f, %.0f],  d[%.3f, %.3f],  g[%.3f]' % (i+1, c_loss, c_acc*100, d_loss1, d_loss2, g_loss))\n",
        "        \n",
        "        # evaluate the model performance every so often\n",
        "        if (i+1) % (bat_per_epo * 1) == 0:\n",
        "            summarize_performance(i, g_model, c_model, latent_dim, dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDTSUy6BskEd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwKgVzy7meH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e614fa-bd0d-4f29-bdb2-5ab520858adb"
      },
      "source": [
        "#==========================================Train Model=========================================\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "\n",
        "# create the discriminator models\n",
        "d_model, c_model = define_discriminator()\n",
        "\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "\n",
        "# train model\n",
        "train(g_model, d_model, c_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training dataset:  X_train:  (688, 12, 1) y_train:  (688,)\n",
            "Supervised dataset:  (800, 12, 1) (800,)\n",
            "n_epochs = 50, n_batch = 100, half_batch = 50, bat_per_epo = 6, steps = 300\n",
            "WARNING:tensorflow:5 out of the last 1201 calls to <function Model.make_train_function.<locals>.train_function at 0x7f4e96c058c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "step: 1,  c[1.034, 56],  d[0.317, 1.850],  g[0.407]\n",
            "step: 2,  c[0.399, 82],  d[0.232, 1.511],  g[0.409]\n",
            "step: 3,  c[0.255, 86],  d[0.242, 1.126],  g[0.411]\n",
            "step: 4,  c[0.103, 98],  d[0.238, 0.773],  g[0.413]\n",
            "step: 5,  c[0.044, 100],  d[0.125, 0.473],  g[0.416]\n",
            "step: 6,  c[0.257, 94],  d[0.178, 0.376],  g[0.418]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0006.h5, and c_model_SGAN_0006.h5\n",
            "\n",
            "step: 7,  c[0.666, 48],  d[0.169, 0.323],  g[0.419]\n",
            "step: 8,  c[0.021, 100],  d[0.055, 0.223],  g[0.422]\n",
            "step: 9,  c[0.177, 98],  d[0.087, 0.159],  g[0.423]\n",
            "step: 10,  c[0.003, 100],  d[0.135, 0.124],  g[0.427]\n",
            "step: 11,  c[0.080, 98],  d[0.029, 0.124],  g[0.428]\n",
            "step: 12,  c[0.157, 98],  d[0.055, 0.070],  g[0.428]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0012.h5, and c_model_SGAN_0012.h5\n",
            "\n",
            "step: 13,  c[0.677, 49],  d[0.030, 0.083],  g[0.432]\n",
            "step: 14,  c[0.006, 100],  d[0.048, 0.092],  g[0.432]\n",
            "step: 15,  c[0.388, 96],  d[0.024, 0.040],  g[0.433]\n",
            "step: 16,  c[0.128, 96],  d[0.038, 0.044],  g[0.434]\n",
            "step: 17,  c[0.302, 96],  d[0.041, 0.036],  g[0.437]\n",
            "step: 18,  c[0.857, 92],  d[0.049, 0.043],  g[0.439]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0018.h5, and c_model_SGAN_0018.h5\n",
            "\n",
            "step: 19,  c[0.671, 48],  d[0.023, 0.041],  g[0.438]\n",
            "step: 20,  c[0.032, 100],  d[0.028, 0.040],  g[0.441]\n",
            "step: 21,  c[0.413, 90],  d[0.027, 0.039],  g[0.441]\n",
            "step: 22,  c[0.206, 92],  d[0.018, 0.025],  g[0.445]\n",
            "step: 23,  c[0.277, 96],  d[0.022, 0.054],  g[0.445]\n",
            "step: 24,  c[0.049, 98],  d[0.015, 0.038],  g[0.445]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0024.h5, and c_model_SGAN_0024.h5\n",
            "\n",
            "step: 25,  c[0.656, 49],  d[0.011, 0.046],  g[0.449]\n",
            "step: 26,  c[0.020, 100],  d[0.017, 0.023],  g[0.448]\n",
            "step: 27,  c[0.157, 96],  d[0.016, 0.024],  g[0.449]\n",
            "step: 28,  c[0.026, 100],  d[0.022, 0.026],  g[0.451]\n",
            "step: 29,  c[0.043, 96],  d[0.015, 0.026],  g[0.455]\n",
            "step: 30,  c[0.088, 96],  d[0.028, 0.017],  g[0.450]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0030.h5, and c_model_SGAN_0030.h5\n",
            "\n",
            "step: 31,  c[0.664, 49],  d[0.015, 0.022],  g[0.451]\n",
            "step: 32,  c[0.099, 98],  d[0.018, 0.019],  g[0.457]\n",
            "step: 33,  c[0.152, 98],  d[0.034, 0.024],  g[0.453]\n",
            "step: 34,  c[0.087, 96],  d[0.008, 0.030],  g[0.459]\n",
            "step: 35,  c[0.012, 100],  d[0.010, 0.016],  g[0.456]\n",
            "step: 36,  c[0.099, 96],  d[0.011, 0.017],  g[0.458]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0036.h5, and c_model_SGAN_0036.h5\n",
            "\n",
            "step: 37,  c[0.671, 49],  d[0.007, 0.026],  g[0.459]\n",
            "step: 38,  c[0.011, 100],  d[0.007, 0.016],  g[0.459]\n",
            "step: 39,  c[0.006, 100],  d[0.006, 0.018],  g[0.466]\n",
            "step: 40,  c[0.017, 100],  d[0.004, 0.019],  g[0.463]\n",
            "step: 41,  c[0.080, 98],  d[0.004, 0.017],  g[0.464]\n",
            "step: 42,  c[0.006, 100],  d[0.002, 0.015],  g[0.465]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0042.h5, and c_model_SGAN_0042.h5\n",
            "\n",
            "step: 43,  c[0.692, 48],  d[0.004, 0.012],  g[0.462]\n",
            "step: 44,  c[0.003, 100],  d[0.007, 0.023],  g[0.462]\n",
            "step: 45,  c[0.276, 94],  d[0.004, 0.015],  g[0.463]\n",
            "step: 46,  c[0.234, 96],  d[0.008, 0.012],  g[0.463]\n",
            "step: 47,  c[0.075, 98],  d[0.007, 0.032],  g[0.476]\n",
            "step: 48,  c[0.086, 96],  d[0.006, 0.029],  g[0.462]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0048.h5, and c_model_SGAN_0048.h5\n",
            "\n",
            "step: 49,  c[0.692, 49],  d[0.004, 0.013],  g[0.462]\n",
            "step: 50,  c[0.013, 100],  d[0.006, 0.016],  g[0.463]\n",
            "step: 51,  c[0.463, 94],  d[0.004, 0.009],  g[0.467]\n",
            "step: 52,  c[0.228, 98],  d[0.008, 0.013],  g[0.471]\n",
            "step: 53,  c[0.025, 98],  d[0.012, 0.011],  g[0.467]\n",
            "step: 54,  c[0.028, 100],  d[0.006, 0.010],  g[0.476]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0054.h5, and c_model_SGAN_0054.h5\n",
            "\n",
            "step: 55,  c[0.710, 49],  d[0.010, 0.012],  g[0.476]\n",
            "step: 56,  c[0.096, 94],  d[0.004, 0.017],  g[0.464]\n",
            "step: 57,  c[0.009, 100],  d[0.004, 0.010],  g[0.468]\n",
            "step: 58,  c[0.056, 94],  d[0.005, 0.007],  g[0.472]\n",
            "step: 59,  c[0.010, 100],  d[0.004, 0.011],  g[0.477]\n",
            "step: 60,  c[0.266, 96],  d[0.006, 0.010],  g[0.481]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0060.h5, and c_model_SGAN_0060.h5\n",
            "\n",
            "step: 61,  c[0.719, 49],  d[0.003, 0.010],  g[0.466]\n",
            "step: 62,  c[0.065, 98],  d[0.006, 0.011],  g[0.472]\n",
            "step: 63,  c[0.152, 96],  d[0.004, 0.009],  g[0.467]\n",
            "step: 64,  c[0.026, 98],  d[0.004, 0.014],  g[0.459]\n",
            "step: 65,  c[0.167, 96],  d[0.004, 0.008],  g[0.484]\n",
            "step: 66,  c[0.002, 100],  d[0.007, 0.017],  g[0.478]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0066.h5, and c_model_SGAN_0066.h5\n",
            "\n",
            "step: 67,  c[0.728, 49],  d[0.008, 0.012],  g[0.468]\n",
            "step: 68,  c[0.360, 94],  d[0.009, 0.009],  g[0.481]\n",
            "step: 69,  c[0.432, 92],  d[0.008, 0.009],  g[0.481]\n",
            "step: 70,  c[0.245, 92],  d[0.004, 0.010],  g[0.477]\n",
            "step: 71,  c[0.077, 98],  d[0.004, 0.016],  g[0.483]\n",
            "step: 72,  c[0.010, 100],  d[0.003, 0.009],  g[0.487]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0072.h5, and c_model_SGAN_0072.h5\n",
            "\n",
            "step: 73,  c[0.721, 49],  d[0.003, 0.007],  g[0.467]\n",
            "step: 74,  c[0.238, 98],  d[0.006, 0.011],  g[0.472]\n",
            "step: 75,  c[0.004, 100],  d[0.003, 0.016],  g[0.474]\n",
            "step: 76,  c[0.112, 98],  d[0.004, 0.008],  g[0.469]\n",
            "step: 77,  c[0.003, 100],  d[0.003, 0.009],  g[0.470]\n",
            "step: 78,  c[0.122, 98],  d[0.007, 0.007],  g[0.473]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0078.h5, and c_model_SGAN_0078.h5\n",
            "\n",
            "step: 79,  c[0.732, 49],  d[0.004, 0.007],  g[0.474]\n",
            "step: 80,  c[0.007, 100],  d[0.005, 0.007],  g[0.458]\n",
            "step: 81,  c[0.061, 98],  d[0.003, 0.010],  g[0.480]\n",
            "step: 82,  c[0.007, 100],  d[0.005, 0.010],  g[0.461]\n",
            "step: 83,  c[0.043, 98],  d[0.003, 0.010],  g[0.472]\n",
            "step: 84,  c[0.130, 98],  d[0.006, 0.005],  g[0.471]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0084.h5, and c_model_SGAN_0084.h5\n",
            "\n",
            "step: 85,  c[0.703, 49],  d[0.002, 0.012],  g[0.467]\n",
            "step: 86,  c[0.003, 100],  d[0.004, 0.010],  g[0.479]\n",
            "step: 87,  c[0.010, 100],  d[0.003, 0.021],  g[0.470]\n",
            "step: 88,  c[0.251, 98],  d[0.003, 0.007],  g[0.472]\n",
            "step: 89,  c[0.002, 100],  d[0.002, 0.013],  g[0.477]\n",
            "step: 90,  c[0.014, 100],  d[0.001, 0.009],  g[0.456]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0090.h5, and c_model_SGAN_0090.h5\n",
            "\n",
            "step: 91,  c[0.708, 48],  d[0.002, 0.007],  g[0.469]\n",
            "step: 92,  c[0.005, 100],  d[0.004, 0.009],  g[0.449]\n",
            "step: 93,  c[0.014, 100],  d[0.003, 0.008],  g[0.466]\n",
            "step: 94,  c[0.017, 100],  d[0.004, 0.006],  g[0.455]\n",
            "step: 95,  c[0.250, 98],  d[0.003, 0.007],  g[0.460]\n",
            "step: 96,  c[0.004, 100],  d[0.004, 0.014],  g[0.462]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0096.h5, and c_model_SGAN_0096.h5\n",
            "\n",
            "step: 97,  c[0.670, 49],  d[0.003, 0.010],  g[0.469]\n",
            "step: 98,  c[0.018, 100],  d[0.005, 0.006],  g[0.459]\n",
            "step: 99,  c[0.005, 100],  d[0.003, 0.041],  g[0.462]\n",
            "step: 100,  c[0.027, 100],  d[0.010, 0.010],  g[0.453]\n",
            "step: 101,  c[0.161, 96],  d[0.005, 0.008],  g[0.453]\n",
            "step: 102,  c[0.038, 98],  d[0.003, 0.016],  g[0.461]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0102.h5, and c_model_SGAN_0102.h5\n",
            "\n",
            "step: 103,  c[0.662, 49],  d[0.008, 0.007],  g[0.458]\n",
            "step: 104,  c[0.027, 100],  d[0.003, 0.013],  g[0.443]\n",
            "step: 105,  c[0.039, 98],  d[0.003, 0.008],  g[0.432]\n",
            "step: 106,  c[0.008, 100],  d[0.013, 0.008],  g[0.451]\n",
            "step: 107,  c[0.143, 98],  d[0.002, 0.011],  g[0.423]\n",
            "step: 108,  c[0.006, 100],  d[0.003, 0.012],  g[0.444]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0108.h5, and c_model_SGAN_0108.h5\n",
            "\n",
            "step: 109,  c[0.613, 49],  d[0.001, 0.009],  g[0.421]\n",
            "step: 110,  c[0.039, 98],  d[0.002, 0.012],  g[0.422]\n",
            "step: 111,  c[0.010, 100],  d[0.005, 0.009],  g[0.423]\n",
            "step: 112,  c[0.253, 98],  d[0.002, 0.029],  g[0.436]\n",
            "step: 113,  c[0.006, 100],  d[0.004, 0.006],  g[0.426]\n",
            "step: 114,  c[0.023, 100],  d[0.003, 0.005],  g[0.426]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0114.h5, and c_model_SGAN_0114.h5\n",
            "\n",
            "step: 115,  c[0.592, 49],  d[0.007, 0.011],  g[0.434]\n",
            "step: 116,  c[0.002, 100],  d[0.005, 0.006],  g[0.436]\n",
            "step: 117,  c[0.027, 100],  d[0.004, 0.011],  g[0.442]\n",
            "step: 118,  c[0.149, 98],  d[0.004, 0.009],  g[0.431]\n",
            "step: 119,  c[0.279, 96],  d[0.005, 0.005],  g[0.413]\n",
            "step: 120,  c[0.138, 98],  d[0.007, 0.007],  g[0.400]\n",
            "Classifier Accuracy: 45.058%\n",
            ">>Saved: g_model_SGAN_0120.h5, and c_model_SGAN_0120.h5\n",
            "\n",
            "step: 121,  c[0.546, 49],  d[0.007, 0.013],  g[0.415]\n",
            "step: 122,  c[0.005, 100],  d[0.009, 0.006],  g[0.398]\n",
            "step: 123,  c[0.020, 100],  d[0.002, 0.011],  g[0.406]\n",
            "step: 124,  c[0.010, 100],  d[0.002, 0.008],  g[0.406]\n",
            "step: 125,  c[0.016, 100],  d[0.005, 0.005],  g[0.424]\n",
            "step: 126,  c[0.213, 98],  d[0.001, 0.009],  g[0.404]\n",
            "Classifier Accuracy: 46.657%\n",
            ">>Saved: g_model_SGAN_0126.h5, and c_model_SGAN_0126.h5\n",
            "\n",
            "step: 127,  c[0.496, 50],  d[0.002, 0.003],  g[0.402]\n",
            "step: 128,  c[0.040, 100],  d[0.003, 0.006],  g[0.418]\n",
            "step: 129,  c[0.226, 98],  d[0.008, 0.006],  g[0.408]\n",
            "step: 130,  c[0.147, 98],  d[0.001, 0.013],  g[0.407]\n",
            "step: 131,  c[0.254, 96],  d[0.003, 0.005],  g[0.393]\n",
            "step: 132,  c[0.038, 98],  d[0.008, 0.007],  g[0.386]\n",
            "Classifier Accuracy: 77.035%\n",
            ">>Saved: g_model_SGAN_0132.h5, and c_model_SGAN_0132.h5\n",
            "\n",
            "step: 133,  c[0.465, 78],  d[0.006, 0.006],  g[0.403]\n",
            "step: 134,  c[0.021, 100],  d[0.003, 0.004],  g[0.401]\n",
            "step: 135,  c[0.014, 100],  d[0.003, 0.005],  g[0.380]\n",
            "step: 136,  c[0.002, 100],  d[0.005, 0.005],  g[0.381]\n",
            "step: 137,  c[0.051, 98],  d[0.002, 0.015],  g[0.375]\n",
            "step: 138,  c[0.007, 100],  d[0.002, 0.005],  g[0.372]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0138.h5, and c_model_SGAN_0138.h5\n",
            "\n",
            "step: 139,  c[0.363, 99],  d[0.002, 0.006],  g[0.386]\n",
            "step: 140,  c[0.259, 96],  d[0.002, 0.005],  g[0.381]\n",
            "step: 141,  c[0.007, 100],  d[0.003, 0.006],  g[0.381]\n",
            "step: 142,  c[0.126, 96],  d[0.003, 0.007],  g[0.345]\n",
            "step: 143,  c[0.052, 98],  d[0.003, 0.014],  g[0.363]\n",
            "step: 144,  c[0.019, 100],  d[0.002, 0.007],  g[0.381]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0144.h5, and c_model_SGAN_0144.h5\n",
            "\n",
            "step: 145,  c[0.354, 99],  d[0.004, 0.007],  g[0.362]\n",
            "step: 146,  c[0.178, 98],  d[0.011, 0.016],  g[0.356]\n",
            "step: 147,  c[0.189, 98],  d[0.004, 0.005],  g[0.384]\n",
            "step: 148,  c[0.270, 98],  d[0.002, 0.007],  g[0.357]\n",
            "step: 149,  c[0.018, 100],  d[0.003, 0.013],  g[0.360]\n",
            "step: 150,  c[0.104, 98],  d[0.003, 0.005],  g[0.400]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0150.h5, and c_model_SGAN_0150.h5\n",
            "\n",
            "step: 151,  c[0.317, 99],  d[0.005, 0.005],  g[0.396]\n",
            "step: 152,  c[0.007, 100],  d[0.010, 0.017],  g[0.343]\n",
            "step: 153,  c[0.035, 98],  d[0.005, 0.018],  g[0.368]\n",
            "step: 154,  c[0.221, 94],  d[0.008, 0.004],  g[0.382]\n",
            "step: 155,  c[0.150, 98],  d[0.019, 0.007],  g[0.336]\n",
            "step: 156,  c[0.033, 98],  d[0.003, 0.004],  g[0.335]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0156.h5, and c_model_SGAN_0156.h5\n",
            "\n",
            "step: 157,  c[0.267, 99],  d[0.003, 0.007],  g[0.306]\n",
            "step: 158,  c[0.121, 98],  d[0.005, 0.004],  g[0.308]\n",
            "step: 159,  c[0.207, 96],  d[0.006, 0.008],  g[0.315]\n",
            "step: 160,  c[0.046, 98],  d[0.003, 0.029],  g[0.331]\n",
            "step: 161,  c[0.244, 96],  d[0.006, 0.003],  g[0.390]\n",
            "step: 162,  c[0.047, 98],  d[0.012, 0.003],  g[0.318]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0162.h5, and c_model_SGAN_0162.h5\n",
            "\n",
            "step: 163,  c[0.236, 99],  d[0.002, 0.004],  g[0.309]\n",
            "step: 164,  c[0.013, 100],  d[0.003, 0.004],  g[0.281]\n",
            "step: 165,  c[0.005, 100],  d[0.001, 0.002],  g[0.269]\n",
            "step: 166,  c[0.014, 100],  d[0.001, 0.006],  g[0.256]\n",
            "step: 167,  c[0.055, 98],  d[0.002, 0.003],  g[0.262]\n",
            "step: 168,  c[0.006, 100],  d[0.002, 0.004],  g[0.259]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0168.h5, and c_model_SGAN_0168.h5\n",
            "\n",
            "step: 169,  c[0.162, 99],  d[0.002, 0.004],  g[0.268]\n",
            "step: 170,  c[0.458, 96],  d[0.001, 0.003],  g[0.265]\n",
            "step: 171,  c[0.092, 98],  d[0.001, 0.003],  g[0.292]\n",
            "step: 172,  c[0.019, 100],  d[0.018, 0.004],  g[0.241]\n",
            "step: 173,  c[0.021, 100],  d[0.002, 0.004],  g[0.232]\n",
            "step: 174,  c[0.016, 100],  d[0.001, 0.003],  g[0.233]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0174.h5, and c_model_SGAN_0174.h5\n",
            "\n",
            "step: 175,  c[0.120, 99],  d[0.001, 0.015],  g[0.227]\n",
            "step: 176,  c[0.008, 100],  d[0.008, 0.003],  g[0.197]\n",
            "step: 177,  c[0.008, 100],  d[0.002, 0.004],  g[0.216]\n",
            "step: 178,  c[0.209, 98],  d[0.001, 0.007],  g[0.193]\n",
            "step: 179,  c[0.116, 98],  d[0.001, 0.004],  g[0.211]\n",
            "step: 180,  c[0.007, 100],  d[0.003, 0.009],  g[0.234]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0180.h5, and c_model_SGAN_0180.h5\n",
            "\n",
            "step: 181,  c[0.108, 99],  d[0.005, 0.003],  g[0.195]\n",
            "step: 182,  c[0.023, 98],  d[0.002, 0.005],  g[0.205]\n",
            "step: 183,  c[0.004, 100],  d[0.010, 0.010],  g[0.180]\n",
            "step: 184,  c[0.097, 98],  d[0.004, 0.003],  g[0.208]\n",
            "step: 185,  c[0.199, 98],  d[0.001, 0.005],  g[0.191]\n",
            "step: 186,  c[0.018, 100],  d[0.002, 0.004],  g[0.207]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0186.h5, and c_model_SGAN_0186.h5\n",
            "\n",
            "step: 187,  c[0.106, 99],  d[0.001, 0.003],  g[0.173]\n",
            "step: 188,  c[0.140, 96],  d[0.003, 0.004],  g[0.221]\n",
            "step: 189,  c[0.046, 98],  d[0.002, 0.014],  g[0.215]\n",
            "step: 190,  c[0.033, 98],  d[0.003, 0.003],  g[0.194]\n",
            "step: 191,  c[0.009, 100],  d[0.007, 0.005],  g[0.206]\n",
            "step: 192,  c[0.016, 100],  d[0.002, 0.015],  g[0.233]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0192.h5, and c_model_SGAN_0192.h5\n",
            "\n",
            "step: 193,  c[0.097, 99],  d[0.006, 0.005],  g[0.189]\n",
            "step: 194,  c[0.011, 100],  d[0.005, 0.005],  g[0.151]\n",
            "step: 195,  c[0.020, 98],  d[0.001, 0.003],  g[0.190]\n",
            "step: 196,  c[0.003, 100],  d[0.001, 0.004],  g[0.150]\n",
            "step: 197,  c[0.021, 100],  d[0.001, 0.003],  g[0.173]\n",
            "step: 198,  c[0.022, 100],  d[0.002, 0.003],  g[0.137]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0198.h5, and c_model_SGAN_0198.h5\n",
            "\n",
            "step: 199,  c[0.063, 99],  d[0.000, 0.004],  g[0.150]\n",
            "step: 200,  c[0.102, 98],  d[0.001, 0.002],  g[0.149]\n",
            "step: 201,  c[0.152, 98],  d[0.001, 0.012],  g[0.121]\n",
            "step: 202,  c[0.007, 100],  d[0.003, 0.004],  g[0.186]\n",
            "step: 203,  c[0.004, 100],  d[0.004, 0.004],  g[0.177]\n",
            "step: 204,  c[0.016, 100],  d[0.002, 0.002],  g[0.142]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0204.h5, and c_model_SGAN_0204.h5\n",
            "\n",
            "step: 205,  c[0.063, 99],  d[0.001, 0.005],  g[0.150]\n",
            "step: 206,  c[0.006, 100],  d[0.001, 0.005],  g[0.177]\n",
            "step: 207,  c[0.002, 100],  d[0.001, 0.010],  g[0.139]\n",
            "step: 208,  c[0.096, 98],  d[0.001, 0.003],  g[0.142]\n",
            "step: 209,  c[0.010, 100],  d[0.002, 0.003],  g[0.197]\n",
            "step: 210,  c[0.008, 100],  d[0.003, 0.002],  g[0.165]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0210.h5, and c_model_SGAN_0210.h5\n",
            "\n",
            "step: 211,  c[0.056, 99],  d[0.001, 0.003],  g[0.140]\n",
            "step: 212,  c[0.009, 100],  d[0.001, 0.005],  g[0.144]\n",
            "step: 213,  c[0.005, 100],  d[0.003, 0.002],  g[0.165]\n",
            "step: 214,  c[0.004, 100],  d[0.001, 0.004],  g[0.113]\n",
            "step: 215,  c[0.111, 98],  d[0.001, 0.004],  g[0.115]\n",
            "step: 216,  c[0.002, 100],  d[0.011, 0.004],  g[0.100]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0216.h5, and c_model_SGAN_0216.h5\n",
            "\n",
            "step: 217,  c[0.056, 99],  d[0.001, 0.005],  g[0.085]\n",
            "step: 218,  c[0.004, 100],  d[0.001, 0.011],  g[0.113]\n",
            "step: 219,  c[0.053, 98],  d[0.000, 0.005],  g[0.152]\n",
            "step: 220,  c[0.008, 100],  d[0.001, 0.002],  g[0.115]\n",
            "step: 221,  c[0.005, 100],  d[0.001, 0.001],  g[0.122]\n",
            "step: 222,  c[0.189, 96],  d[0.002, 0.004],  g[0.133]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0222.h5, and c_model_SGAN_0222.h5\n",
            "\n",
            "step: 223,  c[0.076, 99],  d[0.002, 0.004],  g[0.147]\n",
            "step: 224,  c[0.081, 98],  d[0.005, 0.001],  g[0.193]\n",
            "step: 225,  c[0.246, 94],  d[0.003, 0.003],  g[0.156]\n",
            "step: 226,  c[0.026, 100],  d[0.001, 0.002],  g[0.142]\n",
            "step: 227,  c[0.039, 100],  d[0.002, 0.002],  g[0.130]\n",
            "step: 228,  c[0.218, 94],  d[0.002, 0.004],  g[0.134]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0228.h5, and c_model_SGAN_0228.h5\n",
            "\n",
            "step: 229,  c[0.053, 99],  d[0.001, 0.004],  g[0.126]\n",
            "step: 230,  c[0.083, 98],  d[0.001, 0.003],  g[0.125]\n",
            "step: 231,  c[0.096, 98],  d[0.001, 0.004],  g[0.126]\n",
            "step: 232,  c[0.013, 100],  d[0.002, 0.006],  g[0.122]\n",
            "step: 233,  c[0.186, 96],  d[0.001, 0.003],  g[0.104]\n",
            "step: 234,  c[0.009, 100],  d[0.001, 0.002],  g[0.111]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0234.h5, and c_model_SGAN_0234.h5\n",
            "\n",
            "step: 235,  c[0.067, 99],  d[0.001, 0.006],  g[0.145]\n",
            "step: 236,  c[0.011, 100],  d[0.002, 0.002],  g[0.100]\n",
            "step: 237,  c[0.024, 100],  d[0.001, 0.003],  g[0.113]\n",
            "step: 238,  c[0.009, 100],  d[0.002, 0.035],  g[0.249]\n",
            "step: 239,  c[0.013, 100],  d[0.005, 0.002],  g[0.361]\n",
            "step: 240,  c[0.089, 98],  d[0.010, 0.003],  g[0.191]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0240.h5, and c_model_SGAN_0240.h5\n",
            "\n",
            "step: 241,  c[0.066, 99],  d[0.001, 0.002],  g[0.187]\n",
            "step: 242,  c[0.057, 96],  d[0.001, 0.002],  g[0.161]\n",
            "step: 243,  c[0.267, 96],  d[0.001, 0.044],  g[0.229]\n",
            "step: 244,  c[0.027, 100],  d[0.003, 0.002],  g[0.363]\n",
            "step: 245,  c[0.045, 98],  d[0.007, 0.002],  g[0.195]\n",
            "step: 246,  c[0.162, 96],  d[0.001, 0.018],  g[0.257]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0246.h5, and c_model_SGAN_0246.h5\n",
            "\n",
            "step: 247,  c[0.055, 99],  d[0.003, 0.002],  g[0.265]\n",
            "step: 248,  c[0.023, 98],  d[0.001, 0.001],  g[0.252]\n",
            "step: 249,  c[0.012, 100],  d[0.003, 0.001],  g[0.200]\n",
            "step: 250,  c[0.008, 100],  d[0.002, 0.001],  g[0.201]\n",
            "step: 251,  c[0.117, 98],  d[0.003, 0.001],  g[0.200]\n",
            "step: 252,  c[0.441, 96],  d[0.001, 0.003],  g[0.341]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0252.h5, and c_model_SGAN_0252.h5\n",
            "\n",
            "step: 253,  c[0.073, 99],  d[0.002, 0.003],  g[0.211]\n",
            "step: 254,  c[0.010, 100],  d[0.001, 0.001],  g[0.254]\n",
            "step: 255,  c[0.060, 98],  d[0.007, 0.002],  g[0.184]\n",
            "step: 256,  c[0.007, 100],  d[0.001, 0.005],  g[0.162]\n",
            "step: 257,  c[0.148, 96],  d[0.001, 0.002],  g[0.194]\n",
            "step: 258,  c[0.011, 100],  d[0.001, 0.002],  g[0.208]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0258.h5, and c_model_SGAN_0258.h5\n",
            "\n",
            "step: 259,  c[0.074, 99],  d[0.001, 0.002],  g[0.107]\n",
            "step: 260,  c[0.012, 100],  d[0.000, 0.001],  g[0.183]\n",
            "step: 261,  c[0.010, 100],  d[0.001, 0.002],  g[0.128]\n",
            "step: 262,  c[0.007, 100],  d[0.001, 0.002],  g[0.134]\n",
            "step: 263,  c[0.024, 100],  d[0.001, 0.002],  g[0.148]\n",
            "step: 264,  c[0.014, 100],  d[0.000, 0.002],  g[0.186]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0264.h5, and c_model_SGAN_0264.h5\n",
            "\n",
            "step: 265,  c[0.066, 99],  d[0.001, 0.002],  g[0.145]\n",
            "step: 266,  c[0.006, 100],  d[0.000, 0.002],  g[0.105]\n",
            "step: 267,  c[0.003, 100],  d[0.000, 0.001],  g[0.131]\n",
            "step: 268,  c[0.004, 100],  d[0.000, 0.002],  g[0.175]\n",
            "step: 269,  c[0.010, 100],  d[0.001, 0.002],  g[0.123]\n",
            "step: 270,  c[0.002, 100],  d[0.001, 0.002],  g[0.112]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0270.h5, and c_model_SGAN_0270.h5\n",
            "\n",
            "step: 271,  c[0.072, 99],  d[0.000, 0.002],  g[0.121]\n",
            "step: 272,  c[0.002, 100],  d[0.000, 0.003],  g[0.116]\n",
            "step: 273,  c[0.006, 100],  d[0.000, 0.002],  g[0.126]\n",
            "step: 274,  c[0.169, 98],  d[0.000, 0.002],  g[0.113]\n",
            "step: 275,  c[0.010, 100],  d[0.000, 0.001],  g[0.141]\n",
            "step: 276,  c[0.143, 98],  d[0.000, 0.003],  g[0.088]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0276.h5, and c_model_SGAN_0276.h5\n",
            "\n",
            "step: 277,  c[0.067, 99],  d[0.001, 0.002],  g[0.102]\n",
            "step: 278,  c[0.115, 98],  d[0.000, 0.002],  g[0.125]\n",
            "step: 279,  c[0.125, 96],  d[0.001, 0.003],  g[0.127]\n",
            "step: 280,  c[0.002, 100],  d[0.001, 0.003],  g[0.104]\n",
            "step: 281,  c[0.004, 100],  d[0.001, 0.002],  g[0.080]\n",
            "step: 282,  c[0.093, 98],  d[0.001, 0.002],  g[0.189]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0282.h5, and c_model_SGAN_0282.h5\n",
            "\n",
            "step: 283,  c[0.074, 99],  d[0.003, 0.002],  g[0.138]\n",
            "step: 284,  c[0.015, 100],  d[0.001, 0.002],  g[0.111]\n",
            "step: 285,  c[0.007, 100],  d[0.001, 0.001],  g[0.126]\n",
            "step: 286,  c[0.006, 100],  d[0.001, 0.002],  g[0.088]\n",
            "step: 287,  c[0.091, 98],  d[0.001, 0.002],  g[0.189]\n",
            "step: 288,  c[0.088, 98],  d[0.001, 0.003],  g[0.162]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0288.h5, and c_model_SGAN_0288.h5\n",
            "\n",
            "step: 289,  c[0.073, 99],  d[0.002, 0.002],  g[0.210]\n",
            "step: 290,  c[0.008, 100],  d[0.001, 0.001],  g[0.145]\n",
            "step: 291,  c[0.003, 100],  d[0.001, 0.003],  g[0.191]\n",
            "step: 292,  c[0.009, 100],  d[0.001, 0.002],  g[0.202]\n",
            "step: 293,  c[0.006, 100],  d[0.002, 0.002],  g[0.171]\n",
            "step: 294,  c[0.012, 100],  d[0.001, 0.001],  g[0.207]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0294.h5, and c_model_SGAN_0294.h5\n",
            "\n",
            "step: 295,  c[0.077, 99],  d[0.001, 0.001],  g[0.142]\n",
            "step: 296,  c[0.012, 100],  d[0.000, 0.001],  g[0.126]\n",
            "step: 297,  c[0.154, 98],  d[0.000, 0.001],  g[0.131]\n",
            "step: 298,  c[0.044, 98],  d[0.000, 0.001],  g[0.082]\n",
            "step: 299,  c[0.005, 100],  d[0.001, 0.003],  g[0.107]\n",
            "step: 300,  c[0.238, 96],  d[0.000, 0.001],  g[0.180]\n",
            "Classifier Accuracy: 98.837%\n",
            ">>Saved: g_model_SGAN_0300.h5, and c_model_SGAN_0300.h5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pp5uIMh7meL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WN1jHTs7meM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a12662-bd6b-4126-c642-6121841b108b"
      },
      "source": [
        "# load the model#==========================================Test Model=========================================\n",
        "\n",
        "# example of loading the classifier model and generating images\n",
        "from keras.models import load_model\n",
        "\n",
        "# load the model\n",
        "gan_model = load_model('Save_Model/SGAN/c_model_SGAN_0300.h5')\n",
        "gan_model.summary()\n",
        "# # load the dataset\n",
        "(trainX, trainy), (testX, testy) = (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "# # expand to 3d, e.g. add channels\n",
        "trainX = expand_dims(trainX, axis=-1)\n",
        "testX = expand_dims(testX, axis=-1)\n",
        "\n",
        "# # evaluate the model\n",
        "_, train_acc = gan_model.evaluate(trainX, trainy, verbose=0)\n",
        "print('Train Accuracy: %.3f%%' % (train_acc * 100))\n",
        "\n",
        "_, test_acc = gan_model.evaluate(testX, testy, verbose=0)\n",
        "print('Test Accuracy: %.3f%%' % (test_acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input (InputLayer)           [(None, 12, 1)]           0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv1D)            (None, 6, 128)            512       \n",
            "_________________________________________________________________\n",
            "Leaky_ReLU_1 (LeakyReLU)     (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "drop_1 (Dropout)             (None, 6, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv1D)            (None, 3, 128)            49280     \n",
            "_________________________________________________________________\n",
            "Bat_Norm_1 (BatchNormalizati (None, 3, 128)            512       \n",
            "_________________________________________________________________\n",
            "Leaky_ReLU_2 (LeakyReLU)     (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "drop_2 (Dropout)             (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv1D)            (None, 2, 128)            49280     \n",
            "_________________________________________________________________\n",
            "Bat_Norm_2 (BatchNormalizati (None, 2, 128)            512       \n",
            "_________________________________________________________________\n",
            "Leaky_ReLU_3 (LeakyReLU)     (None, 2, 128)            0         \n",
            "_________________________________________________________________\n",
            "drop_3 (Dropout)             (None, 2, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv1D)            (None, 2, 256)            98560     \n",
            "_________________________________________________________________\n",
            "Bat_Norm_3 (BatchNormalizati (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "Leaky_ReLU_4 (LeakyReLU)     (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "drop_4 (Dropout)             (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv1D)            (None, 2, 256)            327936    \n",
            "_________________________________________________________________\n",
            "Bat_Norm_4 (BatchNormalizati (None, 2, 256)            1024      \n",
            "_________________________________________________________________\n",
            "Leaky_ReLU_5 (LeakyReLU)     (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "drop_5 (Dropout)             (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "Flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1026      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 529,666\n",
            "Trainable params: 0\n",
            "Non-trainable params: 529,666\n",
            "_________________________________________________________________\n",
            "Train Accuracy: 98.837%\n",
            "Test Accuracy: 99.422%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsw0WOCuDNa8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DzDSpFzSo6Q",
        "outputId": "eb8966b8-2f75-4883-876f-fad28d69574f"
      },
      "source": [
        "# Test model\n",
        "test_model = gan_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwaUqzWx7meM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix\n",
        "import itertools\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "\n",
        "def plot_confusion_matrix(cm, classes=None,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    mpl.rcParams.update(mpl.rcParamsDefault)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        " \n",
        "    print(cm)\n",
        "    plt.figure(figsize=(5, 5)) \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar(shrink=0.75)\n",
        "    tick_marks = np.arange(len(list(range(cm.shape[0]))))\n",
        "#     plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes,rotation=90)\n",
        " \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        " \n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    return plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "MARH95wsQIma",
        "outputId": "1bfad8f3-4b4d-4847-f0e1-e51bc3b48f23"
      },
      "source": [
        "pred = np.argmax(gan_model.predict(testX), axis=1).reshape(-1,1)\n",
        "# utils.confusion_plot(pred,data.y_test)\n",
        "plot_confusion_matrix(confusion_matrix(testy,pred),  normalize=True,title=None)\n",
        "plt.savefig(\"confusion matrixa.pdf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n",
            "[[1.         0.        ]\n",
            " [0.01234568 0.98765432]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPuJQ7i0QUQs"
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUWVRxgaQXoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459b5e6a-8619-4205-eab7-b686a9b40b00"
      },
      "source": [
        "!pip install pyshark\n",
        "import pyshark\n",
        "cap = pyshark.FileCapture('goose.pcapng')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyshark in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pyshark) (4.2.6)\n",
            "Requirement already satisfied: py in /usr/local/lib/python3.7/dist-packages (from pyshark) (1.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}